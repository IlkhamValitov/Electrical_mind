<html lang="ru">
    <head>  
        <meta charset="utf-8"/>
        <title>Electrical mind</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="stylesheet" href="style/style.css">
        <script src="script/jquery.js"></script>
        <script src="script/script.js"></script>
        <script src="script/ajax.js"></script>
    </head>
    <body> 
        <div id="outer_container">
            <div class="main_container">
                <header class="header_block">
                    <div class="logo">
                        <h2 class="first_word">Electrical</h2>
                        <h2 class="second_word">Mind</h2>
                    </div>
                    
                    <nav class="navigate_block">
                        <a href="#" accesskey="0" class="button">Галерея</a>
                        <a href="#" accesskey="1" class="button">Экскурс в инсторию</a>
                        <a href="#" accesskey="2" class="button">О чем речь?</a>
                        <a href="#" accesskey="3" class="button">Контакты</a>
                    </nav>

                </header>
                <div class="center_block">
                    <section class="center_section">
                        <div class="main_topic_block">
                            <h1 class="main_topic">Искусственный интеллект: из вымысла в светлое будущее</h1>
                            <!-- <img src="img/1609.jpg"/> -->
                        </div>
                        
                        
                        <h3 class="news_title">Новости</h3>
                        
                        <div class="news_container">
                            <div class="certain_news">
                                <div class="img_container">
                                    <img src="img/Michael_Jordan.jpg">
                                </div>

                                <div class="text_container">
                                    <h4 class="certain_news_title">Почему современные системы искусственного интеллекта 
                                        на самом деле не являются интеллектуальными</h4>
                                    <p>
                                        Системы искусственного интеллекта далеко не настолько развиты, 
                                        чтобы заменить людей во многих задачах, связанных с рассуждением, 
                                        получением знаний из реального мира и социальным взаимодействием.
                                    </p>
                                </div>

                            </div>

                            <div class="certain_news">
                                <div class="img_container">
                                    <img src="img/AI-and-robotics.jpeg">
                                </div>

                                <div class="text_container">
                                    <h4 class="certain_news_title">Люди морально не готовы к «миру постправды» ИИ</h4>
                                    <p>
                                        Год назад вы не часто слышали об ИИ в обычном разговоре, но сегодня, 
                                        кажется, постоянно говорят о том, как генеративные инструменты ИИ, 
                                        такие как ChatGPT и DALL-E, повлияют на будущее работы, распространение 
                                        информации и многое другое
                                    </p>
                                </div>

                            </div>
                        </div>
                        
                        <h3 class="article_title">Избранная статья</h3>
                        <div class="featured_article_block">
                            <div class="featured_article">
                                <h4 class="featured_article_title">
                                    Комиссия ЕС: технологические гиганты должны маркировать контент, созданный ИИ
                                </h4>
                                <p>
                                    Европейская комиссия призывает технологических гигантов, таких как Google, 
                                    Facebook и TikTok, четко маркировать контент, созданный ИИ, по мере 
                                    распространения дезинформации.
                                </p><br>
                                <p>
                                    В целях борьбы с распространением дезинформации в Интернете Европейская комиссия 
                                    призывает крупные технологические компании, такие как Google, Facebook и TikTok, 
                                    активно маркировать контент, созданный искусственным интеллектом, еще до того, как 
                                    будут официально установлены цифровые правила.
                                </p><br>
                                <p>
                                    Комиссия в своем уставе по борьбе с дезинформацией теперь призывает многочисленные 
                                    известные технологические компании содействовать выявлению фактической информации 
                                    среди моря дезинформации.
                                </p><br>
                                <p>
                                    Вера Юрова, вице-президент по ценностям и прозрачности, подчеркнула необходимость 
                                    того, чтобы подписанты предлагали услуги, которые потенциально могут распространять 
                                    дезинформацию, созданную ИИ, для внедрения технологий, способных идентифицировать 
                                    такой контент.
                                </p><br>
                                <p>
                                    Затем эти компании должны четко обозначить этот контент для пользователей, как ранее 
                                    упоминала Юрова в Brussels Playbook.
                                </p><br>
                                <p>
                                    Согласно Закону о цифровых услугах (DSA), крупные онлайн-платформы и поисковые системы, 
                                    такие как Meta, Twitter и TikTok, должны будут к 25 августа выявлять дипфейки — 
                                    сгенерированные или обработанные изображения, аудио и видео — с «заметными метками». или 
                                    же рискнуть столкнуться с существенными штрафами в диапазоне нескольких миллионов евро.
                                </p><br>
                                <p>
                                    Кроме того, Европейский парламент настаивает на том, чтобы аналогичное положение 
                                    охватывало все компании, производящие контент, созданный с помощью ИИ, включая текст, 
                                    в соответствии с предстоящим Законом об искусственном интеллекте, который потенциально 
                                    может вступить в силу уже в 2025 году.
                                </p><br>
                                <p>
                                    Юрова также призвала такие компании, как Microsoft и Google, разработать защитные меры для 
                                    своих сервисов, включая Bard и Bingchat, чтобы предотвратить использование злоумышленниками 
                                    генеративного ИИ в вредоносных целях.
                                </p><br>
                                <p>
                                    Она сообщила, что генеральный директор Google Сундар Пичаи сообщил ей, что их компания в 
                                    настоящее время работает над такими технологиями.
                                </p><br>
                                <p>
                                    Кроме того, Юрова выразила свое разочарование решением Twitter выйти из добровольного кодекса 
                                    всего за несколько месяцев до вступления в силу DSA, охарактеризовав его как досадную 
                                    конфронтацию, которая не осталась незамеченной в Комиссии.
                                </p><br>
                                <p>
                                    Юрова также подчеркнула важность предоставления участниками кодекса подробных отчетов в 
                                    середине июля.
                                </p><br>
                                <p>
                                    Эти отчеты должны содержать всесторонний анализ их усилий по ограничению распространения 
                                    ложных сведений в своих сетях, а также излагать их планы по минимазации количества 
                                    потенциальной дезинформации, исходящей от генеративного ИИ.
                                </p>

                            </div>

                            <div class="featured_article">
                                <h4 class="featured_article_title">
                                    Желание выжить может вывести ИИ на новый уровень

                                </h4>

                                <h5>
                                    <i>
                                        Исследователи утверждают, что биологический принцип гомеостаза сделает роботов умнее.
                                    </i>
                                </h5>

                                <p>
                                    Художественная литература полна роботов с чувствами.
                                </p><br>

                                <p>
                                    Как тот эмоциональный ребенок Дэвид, которого играет Хейли Джоэл Осмент, в фильме 
                                    «Искусственный интеллект». Или ВАЛЛ•И, у которого явно были чувства к ЕВЕ. Робот в 
                                    «Затерянных в космосе» звучал довольно эмоционально, когда предупреждал Уилла Робинсона 
                                    об опасности. Не говоря уже обо всех этих эмоциональных крушениях поездов, дурацких 
                                    роботах из «Мира Дикого Запада».
                                </p><br>

                                <p>
                                    Но в реальной жизни у роботов не больше чувств, чем у камня, погруженного в новокаин.

                                </p><br>
                                    
                                <p>
                                    Однако может быть способ наделить роботов чувствами, говорят нейробиологи Кингсон Мэн и 
                                    Антонио Дамасио. Просто создайте робота, способного чувствовать опасность для 
                                    собственного существования. Затем ему пришлось бы развивать чувства, чтобы управлять 
                                    поведением, необходимым для обеспечения собственного выживания.
                                </p><br>

                                <p>
                                    «Современным роботам не хватает чувств», — пишут Ман и Дамасио в новой статье (требуется 
                                    подписка) в журнале Nature Machine Intelligence. «Они не предназначены для представления
                                    внутреннего состояния своих операций таким образом, который позволил бы им испытать это 
                                    состояние в ментальном пространстве».
                                    
                                </p><br>

                                <p>
                                    Итак, Мэн и Дамасио предлагают стратегию наполнения машин (таких как роботы или 
                                    человекоподобные андроиды) «искусственным эквивалентом чувств». По своей сути это 
                                    предложение требует машин, предназначенных для соблюдения биологического принципа 
                                    гомеостаза. Это идея о том, что жизнь должна регулировать себя, чтобы оставаться в узком 
                                    диапазоне подходящих условий — например, поддерживать температуру и химический баланс в 
                                    пределах жизнеспособности. Осведомленность разумной машины об аналогичных особенностях 
                                    своего внутреннего состояния сводится к роботизированной версии чувств.
                                </p><br>

                                <p>
                                    Такие чувства не только мотивировали бы самосохраняющее поведение, считают Ман и Дамасио,
                                    но также вдохновить искусственный интеллект на то, чтобы более точно подражать реальному.
                                </p><br>

                                <p>
                                    Типичные «интеллектуальные» машины предназначены для выполнения определенной задачи, 
                                    например, диагностики болезнями, вождением автомобиля, игрой в го или победой в Jeopardy! 
                                    Но интеллект на одной арене не то же самое, что более общий человеческий интеллект, который 
                                    можно использовать, чтобы справиться с всевозможными ситуациями, даже теми, с которыми 
                                    раньше не приходилось сталкиваться. Исследователи долго искали секретный рецепт, как сделать 
                                    роботов умными в более широком смысле.
                                </p><br>

                                <p>
                                    По мнению Мана и Дамасио, недостающим компонентом являются чувства.
                                </p><br>

                                <p>
                                    Чувства возникают из-за потребности выжить. Когда люди поддерживают робота в жизнеспособном
                                    состоянии (все провода подсоединены, ток в нужном количестве, комфортная температура),
                                    роботу не нужно беспокоиться о собственном самосохранении. Так что ему не нужны чувства — 
                                    сигнализирует о том, что что-то нуждается в ремонте.
                                </p><br>

                                <p>
                                    Чувства побуждают живые существа искать оптимальные состояния для выживания, помогая 
                                    гарантировать, что поведение поддерживает необходимый гомеостатический баланс. 
                                    Интеллектуальная машина с чувством собственной уязвимости также должна действовать таким
                                    образом, чтобы свести к минимуму угрозы ее существованию.
                                </p><br>

                                <p>
                                    Однако, чтобы воспринимать такие угрозы, робот должен быть спроектирован так, чтобы понимать 
                                    свое собственное внутреннее состояние.
                                </p><br>

                                <p>
                                    Мэн и Дамасио из Университета Южной Калифорнии говорят, что перспективы создания машин с 
                                    чувствами расширились благодаря недавним разработкам в двух ключевых областях исследований: 
                                    мягкой робототехнике и глубоком обучении. Прогресс в области мягкой робототехники может дать 
                                    сырье для машин с чувствами. Методы глубокого обучения могут обеспечить сложные вычисления,
                                    необходимые для преобразования этих чувств в поведение, поддерживающее существование.
                                </p><br>

                                <p>
                                    Глубокое обучение — это современный потомок старой идеи искусственных нейронных сетей — 
                                    наборов связанных вычислительных элементов, которые имитируют работу нервных клеток в живом 
                                    мозге. Входные данные в нейронную сеть изменяют силу связей между искусственными нейронами,
                                    позволяя сети обнаруживать закономерности во входных данных.
                                </p><br>

                                <p>
                                    Для глубокого обучения требуется несколько слоев нейронной сети. Шаблоны в одном слое, 
                                    подвергаемые внешнему вводу, передаются на следующий уровень, а затем на следующий, что 
                                    позволяет машине различать шаблоны в шаблонах. Глубокое обучение может классифицировать эти 
                                    паттерны по категориям, идентифицируя объекты (например, кошек) или определяя, выявляет ли
                                    компьютерная томография признаки рака или какой-либо другой болезни.
                                </p><br>

                                <p>
                                    Разумный робот, конечно же, должен был бы идентифицировать множество особенностей в своей 
                                    среде, а также отслеживать свое собственное внутреннее состояние. Представляя состояния 
                                    окружающей среды с помощью вычислений, машина глубокого обучения может объединять различные
                                    входные данные для последовательной оценки своей ситуации. Такая умная машина, отмечают 
                                    Мэн и Дамасио, могла бы «пересекать сенсорные модальности» — узнавая, например, как движения 
                                    губ (визуальная модальность) соответствуют вокальным звукам (слуховая модальность).
                                </p><br>

                                <p>
                                    Точно так же этот робот мог связать внешние ситуации со своими внутренними условиями — со 
                                    своими чувствами, если они у него были. Связывание внешних и внутренних условий «обеспечивает 
                                    решающую часть головоломки о том, как переплести внутренние гомеостатические состояния системы
                                    с ее внешним восприятием и поведением», — отмечают Ман и Дамасио.
                                </p><br>

                                <p>
                                    Однако способность ощущать внутренние состояния не имеет большого значения, если только
                                    жизнеспособность этих состояний не уязвима для нападений со стороны окружающей среды. Роботы
                                    из металла не беспокоятся об укусах комаров, порезах бумагой или расстройстве желудка. Но 
                                    если робот будет сделан из надлежащих мягких материалов со встроенными электронными датчиками, 
                                    он сможет обнаружить такие опасности — скажем, порез на «коже», угрожающий его внутренностям,
                                    — и запустить программу для восстановления травмы.
                                </p><br>

                                <p>
                                    Робот, способный воспринимать экзистенциальные риски, может научиться разрабатывать новые
                                    методы своей защиты, вместо того чтобы полагаться на заранее запрограммированные решения.
                                </p><br>

                                <p>
                                    «Вместо того, чтобы жестко запрограммировать робота на все случаи жизни или снабдить его 
                                    ограниченным набором поведенческих политик, робот, заботящийся о собственном выживании, может 
                                    творчески решать проблемы, с которыми он сталкивается», — подозревают Ман и Дамасио. «Основные
                                    цели и ценности будут обнаруживаться органически, а не разрабатываться извне».
                                </p><br>

                                <p>
                                    Разработка новых возможностей самозащиты также может привести к улучшению навыков мышления. 
                                    Мэн и Дамасио считают, что продвинутая человеческая мысль могла развиться именно таким образом: 
                                    поддержание жизнеспособных внутренних состояний (гомеостаза) требовало развития большей мощности
                                    мозга. «Мы рассматриваем высокоуровневое познание как результат ресурсов, возникших для решения
                                    древней биологической проблемы гомеостаза», — пишут Ман и Дамасио.
                                </p><br>

                                <p>
                                    Таким образом, защита собственного существования может быть просто мотивацией, необходимой роботу, 
                                    чтобы в конечном итоге подражать человеческому общему интеллекту. Эта мотивация напоминает 
                                    знаменитые законы робототехники Айзека Азимова: роботы должны защищать людей, роботы должны 
                                    подчиняться людям, роботы должны защищать себя. В произведениях Азимова самозащита подчинялась 
                                    первым двум законам. Таким образом, в реальных роботах будущего могут потребоваться некоторые
                                    меры предосторожности для защиты людей от самозащитных роботов.
                                </p><br>


                                <p>
                                    «Истории о роботах часто плохо заканчиваются для их создателей-людей», — признают Ман и Дамасио. 
                                    Но будет ли суперумный робот (с чувствами) действительно представлять опасность типа Терминатора? 
                                    «Мы не предлагаем, — говорят они, — при условии, например, что, помимо доступа к собственным 
                                    чувствам, оно могло бы знать и о чувствах других, — то есть если бы оно было наделено эмпатией».
                                </p><br>

                                <p>
                                    Итак, Ман и Дамасио предлагают свои правила для роботов: 1. Чувствовать себя хорошо. 2. 
                                    Почувствуйте эмпатию.
                                </p><br>

                                <p>
                                    «Предполагая, что робот уже способен к искренним чувствам, обязательная связь между его чувствами
                                    и чувствами других привела бы к его этичному и общительному поведению», — утверждают нейробиологи.
                                </p><br>

                                <p>
                                    Это может показаться немного оптимистичным. Но если это возможно, может быть, есть надежда на 
                                    лучшее будущее. Если ученым удастся привить эмпатию роботам, возможно, это подскажет способ 
                                    сделать это и у людей.
                                </p><br>


                            </div>

                        </div>

                    </section>

                </div>
                <footer class="footer_block">
                    <nav class="second_nav_block">
                        <a href="#" accesskey="0" class="button">Галерея</a>
                        <a href="#" accesskey="1" class="button">Экскурс в инсторию</a>
                        <a href="#" accesskey="2" class="button">О чем речь?</a>
                        <a href="#" accesskey="3" class="button">Контакты</a>
                    </nav>
                    <p class="author_inf"><a class="link" href="mailto:ilkhamvalitov@gmail.com?subject=Обратная связь">By IV</a></p>

                </footer>

            </div>
        </div>
    </body>
</html>